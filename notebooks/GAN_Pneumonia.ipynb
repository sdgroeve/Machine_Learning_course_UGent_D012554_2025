{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdgroeve/Machine_Learning_course_UGent_D012554_2025/blob/main/notebooks/GAN_Pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seH2IQv9E7wU"
      },
      "source": [
        "# Generative Adversarial Networks (GANs) in Medical Imaging: Pneumonia\n",
        "\n",
        "Generative Adversarial Networks (GANs) are a class of deep learning models that consist of two neural networks - a Generator and a Discriminator - that compete against each other in a minimax game. The Generator creates synthetic data samples, while the Discriminator tries to distinguish between real and generated samples. Through this adversarial process, the Generator learns to produce increasingly realistic data.\n",
        "\n",
        "In medical imaging, GANs have several important applications:\n",
        "- Data augmentation to address limited availability of medical images\n",
        "- Synthetic data generation for rare conditions\n",
        "- Domain adaptation between different imaging modalities\n",
        "- Image enhancement and restoration\n",
        "\n",
        "The notebook demonstrates how to implement a GAN for generating synthetic chest X-ray images of pneumonia using the PneumoniaMNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-apsEmvbQk2q"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "- Installs the medmnist package for accessing medical image datasets\n",
        "- Imports necessary libraries for deep learning (PyTorch), data manipulation, and visualization\n",
        "- Sets a random seed for reproducibility, ensuring the same results can be obtained across different runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTTC7LevFUXn"
      },
      "outputs": [],
      "source": [
        "!pip install medmnist -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z5MFtChE7wX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import medmnist\n",
        "from medmnist import PneumoniaMNIST\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "torch.manual_seed(manualSeed)\n",
        "np.random.seed(manualSeed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5UGOKDwQk2r"
      },
      "source": [
        "## DataLoaders\n",
        "\n",
        "- Defines data transformations to convert images to tensors and normalize them to the range [-1, 1], which is suitable for the Tanh activation in the Generator\n",
        "- Downloads and loads the PneumoniaMNIST dataset, which contains chest X-ray images classified as normal or pneumonia\n",
        "- Creates a DataLoader with a batch size of 128 and shuffling enabled for training\n",
        "- Determines whether to use GPU (CUDA) or CPU for computation\n",
        "- Visualizes a batch of training images to understand the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WAGnxzE7wX"
      },
      "outputs": [],
      "source": [
        "# Data transformations\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5]) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "data_dir = '.' # Directory to save data\n",
        "train_dataset = PneumoniaMNIST(split='train', transform=data_transform, download=True, root=data_dir)\n",
        "\n",
        "batch_size = 128\n",
        "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cbsK_h1Qk2s"
      },
      "source": [
        "## Model\n",
        "\n",
        "Define key configuration parameters:\n",
        "- `nz`: Size of the latent vector (random noise) input to the Generator (100 dimensions)\n",
        "- `nc`: Number of channels in the images (1 for grayscale PneumoniaMNIST images)\n",
        "- `ngf`: Size of feature maps in the Generator (controls network capacity)\n",
        "- `img_size`: Total size of the flattened image (28×28 = 784 pixels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlso1SfuQk2t"
      },
      "outputs": [],
      "source": [
        "nz = 100\n",
        "nc = 1\n",
        "ngf = 64\n",
        "img_size = 28 * 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pio6o_8GQk2t"
      },
      "source": [
        "#### The Generator\n",
        "\n",
        "- Takes random noise as input and transforms it into synthetic images\n",
        "- Uses a fully connected (linear) architecture rather than convolutional layers, which is suitable for the relatively small 28×28 images\n",
        "- Has 4 layers with increasing feature dimensions to progressively build up the image representation:\n",
        "  1. First layer: Transforms latent vector (nz=100) to initial feature representation (ngf*4=256)\n",
        "  2. Second layer: Expands features to ngf*8=512 with batch normalization for training stability\n",
        "  3. Third layer: Further expands features to ngf*16=1024\n",
        "  4. Output layer: Transforms to image dimensions (28*28=784 pixels)\n",
        "- Uses LeakyReLU activations (with negative slope 0.2) for all hidden layers\n",
        "- Uses Tanh activation in the output layer to produce values in the range [-1, 1], matching the normalized input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjdwdeVTE7wY"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, img_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(nz, ngf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ngf * 4, ngf * 8),\n",
        "            nn.BatchNorm1d(ngf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ngf * 8, ngf * 16),\n",
        "            nn.BatchNorm1d(ngf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ngf * 16, img_size),\n",
        "            nn.Tanh()   # Output range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwgQg4aFQk2t"
      },
      "source": [
        "#### The Discriminator\n",
        "\n",
        "- Takes an image as input and outputs a probability indicating whether the image is real or fake\n",
        "- Also uses a fully connected architecture with 4 layers:\n",
        "  1. First layer: Transforms flattened image (784 pixels) to initial feature representation (ndf*16=1024)\n",
        "  2. Second layer: Compresses features to ndf*8=512\n",
        "  3. Third layer: Further compresses features to ndf*4=256\n",
        "  4. Output layer: Single value representing probability of being real\n",
        "- Uses LeakyReLU activations for hidden layers\n",
        "- Uses Sigmoid activation in the output layer to produce a probability between 0 and 1\n",
        "- Flattens the input image in the forward pass before processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPtvbbG5E7wY"
      },
      "outputs": [],
      "source": [
        "ndf = 64\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_size, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(img_size, ndf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ndf * 16, ndf * 8),\n",
        "            nn.BatchNorm1d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ndf * 8, ndf * 4),\n",
        "            nn.BatchNorm1d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(ndf * 4, 1),\n",
        "            nn.Sigmoid() # Output a probability (0-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Flatten the image before passing to linear layers\n",
        "        input = input.view(input.size(0), -1)\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD7_t4igE7wY"
      },
      "source": [
        "## Initialize Models, Loss, and Optimizers\n",
        "\n",
        "- Instantiates the Generator and Discriminator models and moves them to the selected device (GPU/CPU)\n",
        "- Initializes Binary Cross Entropy (BCE) loss function, appropriate for binary classification tasks\n",
        "- Creates a fixed batch of random noise vectors to track Generator progress during training\n",
        "- Establishes label conventions: 1.0 for real images, 0.0 for fake images\n",
        "- Sets up Adam optimizers for both networks with:\n",
        "  - Learning rate of 0.0002\n",
        "  - Beta1 of 0.5 (momentum parameter, lower than the default 0.9, as recommended in the DCGAN paper)\n",
        "- Prints the model architectures for inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M98rRv5E7wZ"
      },
      "outputs": [],
      "source": [
        "# Create the Generator\n",
        "netG = Generator(nz, ngf, img_size).to(device)\n",
        "\n",
        "# Create the Discriminator\n",
        "netD = Discriminator(img_size, ndf).to(device)\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "# the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "lr = 0.0002\n",
        "beta1 = 0.5 # Recommended beta1 for Adam in DCGAN paper\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "print(\"Generator:\", netG)\n",
        "print(\"\\nDiscriminator:\", netD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSoPRxXdQk2u"
      },
      "source": [
        "## Training\n",
        "\n",
        "The training loop implements the GAN training process:\n",
        "\n",
        "1. **Initialization**:\n",
        "   - Creates lists to track progress: generated images, Generator losses, and Discriminator losses\n",
        "   - Sets the number of training epochs to 50\n",
        "   - Creates a directory to save generated images\n",
        "\n",
        "2. **Training Process** (for each epoch and batch):\n",
        "   - **Update Discriminator**:\n",
        "     - Zero the gradients for Discriminator\n",
        "     - Train with real images: Calculate loss for real images (should be classified as 1)\n",
        "     - Train with fake images: Generate fake images, calculate loss (should be classified as 0)\n",
        "     - Compute total Discriminator loss and update parameters\n",
        "     - D(x) represents average prediction on real images (should be close to 1)\n",
        "     - D(G(z)) represents average prediction on fake images (should be close to 0)\n",
        "\n",
        "   - **Update Generator**:\n",
        "     - Zero the gradients for Generator\n",
        "     - Use fake labels as real for Generator cost (we want G to fool D)\n",
        "     - Calculate Generator loss (wants D to predict 1 for fake images)\n",
        "     - Update Generator parameters\n",
        "     - D(G(z)) after update should increase as G improves\n",
        "\n",
        "3. **Monitoring and Visualization**:\n",
        "   - Print training statistics every 50 batches\n",
        "   - Save losses for later plotting\n",
        "   - Periodically generate and save images using fixed noise to track Generator progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWR1CbBEE7wZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "num_epochs = 50 # Adjust as needed, more epochs generally lead to better results but take longer\n",
        "\n",
        "# Create directory for saving generated images\n",
        "output_dir = \"gan_pneumonia_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device) # data[0] contains the images\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1) # .detach() stops gradients flowing back to G\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1) # Don't detach fake here, we need gradients for G\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            # Reshape fake images back to 28x28 grayscale\n",
        "            fake_images = fake.view(fake.size(0), 1, 28, 28) # Reshape to (batch_size, channels, height, width)\n",
        "            img_grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
        "            img_list.append(img_grid)\n",
        "            # Save the image grid\n",
        "            vutils.save_image(img_grid, f\"{output_dir}/fake_samples_epoch_{epoch:03d}_iter_{iters:05d}.png\", normalize=True)\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "print(\"Training Finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIKZxXDGQk2v"
      },
      "source": [
        "## Results\n",
        "\n",
        "- Plots the training losses for both Generator and Discriminator to visualize training progress\n",
        "- Compares real and generated images side by side:\n",
        "  - Left: A batch of real pneumonia X-ray images from the dataset\n",
        "  - Right: The final batch of generated images from the trained Generator\n",
        "- Provides a visual assessment of how well the GAN has learned to generate realistic pneumonia X-ray images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nQiD7XkE7wZ"
      },
      "outputs": [],
      "source": [
        "# Plot training losses\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqnuquYQE7wa"
      },
      "outputs": [],
      "source": [
        "if img_list:\n",
        "    # Grab a batch of real images from the dataloader\n",
        "    real_batch = next(iter(dataloader))\n",
        "\n",
        "    # Plot the real images\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Real Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "    # Plot the fake images from the last saved list item\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Fake Images (Last Epoch)\")\n",
        "    plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No generated images were saved during training (check training loop logic and iterations).\")\n",
        "\n",
        "# You can also view the saved image files in the 'gan_pneumonia_images' directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtbrMhqxQk2v"
      },
      "source": [
        "## Key Concepts in GAN Training\n",
        "\n",
        "### Adversarial Training\n",
        "\n",
        "The core of GAN training is the adversarial process:\n",
        "1. The Discriminator learns to distinguish between real and fake images\n",
        "2. The Generator learns to produce increasingly realistic images to fool the Discriminator\n",
        "3. As training progresses, both networks improve their capabilities\n",
        "\n",
        "### Loss Functions\n",
        "\n",
        "- **Discriminator Loss**: Sum of two components:\n",
        "  - Loss for real images: How well D classifies real images as real\n",
        "  - Loss for fake images: How well D classifies fake images as fake\n",
        "  - Ideal: D(x) ≈ 1 (real images classified as real) and D(G(z)) ≈ 0 (fake images classified as fake)\n",
        "\n",
        "- **Generator Loss**:\n",
        "  - Based on how well G fools D into classifying fake images as real\n",
        "  - Ideal: D(G(z)) ≈ 1 (fake images classified as real by D)\n",
        "\n",
        "### Training Stability\n",
        "\n",
        "GAN training can be unstable. This implementation includes several techniques to improve stability:\n",
        "- Batch normalization in both networks\n",
        "- LeakyReLU activations instead of standard ReLU\n",
        "- Adam optimizer with beta1=0.5\n",
        "- Proper initialization and normalization of input data\n",
        "\n",
        "## Potential Improvements\n",
        "\n",
        "1. **Architecture Enhancements**:\n",
        "   - Use convolutional layers (DCGAN) for better image quality\n",
        "   - Implement more advanced GAN variants like WGAN or StyleGAN\n",
        "\n",
        "2. **Conditional Generation**:\n",
        "   - Add condition labels to create a conditional GAN (cGAN)\n",
        "   - Allow control over the type of images generated\n",
        "\n",
        "3. **Evaluation Metrics**:\n",
        "   - Implement quantitative metrics to evaluate generated image quality\n",
        "   - Use medical-specific metrics for clinical relevance\n",
        "\n",
        "4. **Applications**:\n",
        "   - Use generated images for data augmentation in classification tasks\n",
        "   - Explore domain adaptation between different medical imaging modalities\n",
        "\n",
        "## Ethical Considerations\n",
        "\n",
        "When using GANs for medical imaging:\n",
        "- Synthetic images should be clearly labeled as such\n",
        "- Careful evaluation is necessary before using in clinical applications\n",
        "- Privacy concerns should be addressed when training on patient data\n",
        "- Bias in the training data may be amplified in generated images\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This GAN implementation demonstrates the potential of generative models in medical imaging. While the current implementation uses a simple architecture, it provides a foundation for more advanced approaches that could address challenges in medical image analysis, such as limited data availability and class imbalance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}